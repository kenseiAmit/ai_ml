{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# COLLECTING MORE DATA FROM THE MODERN WEB\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Par one of the book focuses on web scraping machnanics using Python to request information from a web server, performing basic handling of the server's response , and interacting with sites in an automated fashion. \n",
    "\n",
    "Part two rxplores a variety of more spedific tools and application to fint any web scraping scenario you're likely to encounter.\n",
    "\n",
    "1. Parse and complie HTML code\n",
    "2. Develop crawles eith the Scrapy framework\n",
    "3. Lean methods to store data you scrape\n",
    "4. read and sxtract data drom documents\n",
    "5. Clean and normalize badly formatted data\n",
    "6. Read and write natual languages\n",
    "7. Crawl through forms and logisn\n",
    "8. Scrape JavaScript and crawl through APIs\n",
    "9. Use and write image-to-test software\n",
    "10. Avoid scraping traps and bot blockers\n",
    "11 ue scrapers to test your website"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}